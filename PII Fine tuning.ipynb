{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-06-15T04:30:45.352228Z",
     "iopub.status.busy": "2024-06-15T04:30:45.351585Z",
     "iopub.status.idle": "2024-06-15T04:31:19.405658Z",
     "shell.execute_reply": "2024-06-15T04:31:19.404653Z",
     "shell.execute_reply.started": "2024-06-15T04:30:45.352193Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Step 1: Import the HuggingFace datasets library\n",
    "from datasets import load_dataset\n",
    "# Step 2: Define the list of Indian language codes\n",
    "arr=['as', 'bn', 'gu', 'hi', 'kn', 'ml', 'mr', 'or', 'pa', 'ta', 'te']\n",
    "# Step 3: Load the Naamapadam dataset for each language and store in a list\n",
    "k=[]\n",
    "for i in arr:\n",
    "    k.append(load_dataset(\"ai4bharat/naamapadam\",i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T04:31:19.408514Z",
     "iopub.status.busy": "2024-06-15T04:31:19.407916Z",
     "iopub.status.idle": "2024-06-15T04:31:19.416349Z",
     "shell.execute_reply": "2024-06-15T04:31:19.415465Z",
     "shell.execute_reply.started": "2024-06-15T04:31:19.408474Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['tokens', 'ner_tags'],\n",
       "         num_rows: 10266\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['tokens', 'ner_tags'],\n",
       "         num_rows: 51\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['tokens', 'ner_tags'],\n",
       "         num_rows: 52\n",
       "     })\n",
       " }),\n",
       " DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['tokens', 'ner_tags'],\n",
       "         num_rows: 961679\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['tokens', 'ner_tags'],\n",
       "         num_rows: 607\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['tokens', 'ner_tags'],\n",
       "         num_rows: 4859\n",
       "     })\n",
       " }),\n",
       " DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['tokens', 'ner_tags'],\n",
       "         num_rows: 472845\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['tokens', 'ner_tags'],\n",
       "         num_rows: 1076\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['tokens', 'ner_tags'],\n",
       "         num_rows: 2389\n",
       "     })\n",
       " }),\n",
       " DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['tokens', 'ner_tags'],\n",
       "         num_rows: 985787\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['tokens', 'ner_tags'],\n",
       "         num_rows: 867\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['tokens', 'ner_tags'],\n",
       "         num_rows: 13460\n",
       "     })\n",
       " }),\n",
       " DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['tokens', 'ner_tags'],\n",
       "         num_rows: 471763\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['tokens', 'ner_tags'],\n",
       "         num_rows: 1019\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['tokens', 'ner_tags'],\n",
       "         num_rows: 2381\n",
       "     })\n",
       " }),\n",
       " DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['tokens', 'ner_tags'],\n",
       "         num_rows: 716652\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['tokens', 'ner_tags'],\n",
       "         num_rows: 974\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['tokens', 'ner_tags'],\n",
       "         num_rows: 3618\n",
       "     })\n",
       " }),\n",
       " DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['tokens', 'ner_tags'],\n",
       "         num_rows: 455248\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['tokens', 'ner_tags'],\n",
       "         num_rows: 1080\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['tokens', 'ner_tags'],\n",
       "         num_rows: 2300\n",
       "     })\n",
       " }),\n",
       " DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['tokens', 'ner_tags'],\n",
       "         num_rows: 196793\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['tokens', 'ner_tags'],\n",
       "         num_rows: 994\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['tokens', 'ner_tags'],\n",
       "         num_rows: 993\n",
       "     })\n",
       " }),\n",
       " DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['tokens', 'ner_tags'],\n",
       "         num_rows: 463534\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['tokens', 'ner_tags'],\n",
       "         num_rows: 993\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['tokens', 'ner_tags'],\n",
       "         num_rows: 2340\n",
       "     })\n",
       " }),\n",
       " DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['tokens', 'ner_tags'],\n",
       "         num_rows: 497882\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['tokens', 'ner_tags'],\n",
       "         num_rows: 758\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['tokens', 'ner_tags'],\n",
       "         num_rows: 2795\n",
       "     })\n",
       " }),\n",
       " DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['tokens', 'ner_tags'],\n",
       "         num_rows: 507741\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['tokens', 'ner_tags'],\n",
       "         num_rows: 847\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['tokens', 'ner_tags'],\n",
       "         num_rows: 2700\n",
       "     })\n",
       " })]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Display the loaded datasets for all languages\n",
    "k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T04:33:46.445414Z",
     "iopub.status.busy": "2024-06-15T04:33:46.444493Z",
     "iopub.status.idle": "2024-06-15T04:33:46.672084Z",
     "shell.execute_reply": "2024-06-15T04:33:46.671119Z",
     "shell.execute_reply.started": "2024-06-15T04:33:46.445378Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['tokens', 'ner_tags'],\n",
      "        num_rows: 5740190\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['tokens', 'ner_tags'],\n",
      "        num_rows: 9266\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['tokens', 'ner_tags'],\n",
      "        num_rows: 37887\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Import DatasetDict and concatenate_datasets for merging datasets\n",
    "from datasets import DatasetDict, concatenate_datasets\n",
    "# Step 6: Combine all train datasets\n",
    "combined_train = concatenate_datasets([dd['train'] for dd in k])\n",
    "# Step 7: Combine all test datasets\n",
    "combined_test = concatenate_datasets([dd['test'] for dd in k])\n",
    "# Step 8: Combine all validation datasets\n",
    "combined_validation = concatenate_datasets([dd['validation'] for dd in k])\n",
    "# Step 9: Create the final combined DatasetDict\n",
    "combined_dataset = DatasetDict({\n",
    "    'train': combined_train,\n",
    "    'test': combined_test,\n",
    "    'validation': combined_validation\n",
    "})\n",
    "# Step 10: Print and display the combined dataset\n",
    "print(combined_dataset)\n",
    "combined_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-06-15T04:33:46.673828Z",
     "iopub.status.busy": "2024-06-15T04:33:46.673571Z",
     "iopub.status.idle": "2024-06-15T04:33:46.680595Z",
     "shell.execute_reply": "2024-06-15T04:33:46.679522Z",
     "shell.execute_reply.started": "2024-06-15T04:33:46.673805Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Step 11: Get the NER tag feature from the first language's train split\n",
    "ner_feature = k[0][\"train\"].features[\"ner_tags\"]\n",
    "# ner_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T04:33:46.682244Z",
     "iopub.status.busy": "2024-06-15T04:33:46.681856Z",
     "iopub.status.idle": "2024-06-15T04:33:46.687447Z",
     "shell.execute_reply": "2024-06-15T04:33:46.686391Z",
     "shell.execute_reply.started": "2024-06-15T04:33:46.682217Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Step 12: Extract label names for NER tags\n",
    "label_names = ner_feature.feature.names\n",
    "# label_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T04:33:46.690307Z",
     "iopub.status.busy": "2024-06-15T04:33:46.689920Z",
     "iopub.status.idle": "2024-06-15T04:33:46.877857Z",
     "shell.execute_reply": "2024-06-15T04:33:46.876937Z",
     "shell.execute_reply.started": "2024-06-15T04:33:46.690270Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Step 13: Load the tokenizer from HuggingFace Transformers\n",
    "from transformers import AutoTokenizer\n",
    "model_name= \"google-bert/bert-base-uncased\"\n",
    "model_checkpoint =model_name\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T04:33:46.879456Z",
     "iopub.status.busy": "2024-06-15T04:33:46.879136Z",
     "iopub.status.idle": "2024-06-15T04:33:46.885923Z",
     "shell.execute_reply": "2024-06-15T04:33:46.884988Z",
     "shell.execute_reply.started": "2024-06-15T04:33:46.879415Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Step 14: Function to align NER labels with tokenized words\n",
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            label = labels[word_id]\n",
    "            # If the label is B-XXX we change it to I-XXX\n",
    "            if label % 2 == 1:\n",
    "                label += 1\n",
    "            new_labels.append(label)\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T04:35:19.684711Z",
     "iopub.status.busy": "2024-06-15T04:35:19.683975Z",
     "iopub.status.idle": "2024-06-15T04:35:19.690442Z",
     "shell.execute_reply": "2024-06-15T04:35:19.689476Z",
     "shell.execute_reply.started": "2024-06-15T04:35:19.684676Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Step 15: Tokenize and align labels for the dataset\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "    all_labels = examples[\"ner_tags\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T04:35:19.699393Z",
     "iopub.status.busy": "2024-06-15T04:35:19.699118Z",
     "iopub.status.idle": "2024-06-15T04:51:46.841617Z",
     "shell.execute_reply": "2024-06-15T04:51:46.840726Z",
     "shell.execute_reply.started": "2024-06-15T04:35:19.699367Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdc2e945862e4cfbb06e520627b0bea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5740190 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f7f712a25344acd969544495fd21edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9266 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c01dcde3d994f10aa5d251fe9327f75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/37887 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 16: Apply tokenization and label alignment to the combined dataset\n",
    "tokenized_datasets = combined_dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=combined_dataset[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T04:51:46.843386Z",
     "iopub.status.busy": "2024-06-15T04:51:46.843095Z",
     "iopub.status.idle": "2024-06-15T04:51:51.175546Z",
     "shell.execute_reply": "2024-06-15T04:51:51.174487Z",
     "shell.execute_reply.started": "2024-06-15T04:51:46.843359Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-15 04:51:47.817192: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-15 04:51:47.817257: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-15 04:51:47.818765: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "# Step 17: Import and create a data collator for token classification\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T04:51:51.177743Z",
     "iopub.status.busy": "2024-06-15T04:51:51.177125Z",
     "iopub.status.idle": "2024-06-15T04:51:51.187498Z",
     "shell.execute_reply": "2024-06-15T04:51:51.186304Z",
     "shell.execute_reply.started": "2024-06-15T04:51:51.177712Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0, -100],\n",
       "        [-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "         -100, -100]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 18: Create a batch and inspect the labels\n",
    "batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(2)])\n",
    "batch[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T04:51:51.190634Z",
     "iopub.status.busy": "2024-06-15T04:51:51.190197Z",
     "iopub.status.idle": "2024-06-15T04:51:51.199117Z",
     "shell.execute_reply": "2024-06-15T04:51:51.198183Z",
     "shell.execute_reply.started": "2024-06-15T04:51:51.190599Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100]\n",
      "[-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100]\n"
     ]
    }
   ],
   "source": [
    "# Step 19: Print the labels for the first two training samples\n",
    "for i in range(2):\n",
    "    print(tokenized_datasets[\"train\"][i][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T04:51:51.200554Z",
     "iopub.status.busy": "2024-06-15T04:51:51.200215Z",
     "iopub.status.idle": "2024-06-15T04:52:03.790269Z",
     "shell.execute_reply": "2024-06-15T04:52:03.789096Z",
     "shell.execute_reply.started": "2024-06-15T04:51:51.200508Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seqeval in /opt/conda/lib/python3.10/site-packages (1.2.2)\n",
      "Requirement already satisfied: evaluate in /opt/conda/lib/python3.10/site-packages (0.4.2)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.2.2)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.19.2)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.3.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.23.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (14.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Step 20: Install evaluation libraries\n",
    "!pip install seqeval evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T04:52:03.792012Z",
     "iopub.status.busy": "2024-06-15T04:52:03.791709Z",
     "iopub.status.idle": "2024-06-15T04:52:05.609610Z",
     "shell.execute_reply": "2024-06-15T04:52:05.608825Z",
     "shell.execute_reply.started": "2024-06-15T04:52:03.791985Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Step 21: Import the evaluate library and load the seqeval metric\n",
    "import evaluate\n",
    "metric = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T04:52:05.611091Z",
     "iopub.status.busy": "2024-06-15T04:52:05.610797Z",
     "iopub.status.idle": "2024-06-15T04:52:05.615835Z",
     "shell.execute_reply": "2024-06-15T04:52:05.614868Z",
     "shell.execute_reply.started": "2024-06-15T04:52:05.611064Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Step 22: Assign the combined dataset to raw_datasets for evaluation\n",
    "raw_datasets=combined_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T04:52:05.617263Z",
     "iopub.status.busy": "2024-06-15T04:52:05.616999Z",
     "iopub.status.idle": "2024-06-15T04:52:05.628407Z",
     "shell.execute_reply": "2024-06-15T04:52:05.627467Z",
     "shell.execute_reply.started": "2024-06-15T04:52:05.617238Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'O', 'O', 'O', 'O', 'O', 'O']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 23: Convert NER tag indices to label names for the first training sample\n",
    "labels = raw_datasets[\"train\"][0][\"ner_tags\"]\n",
    "labels = [label_names[i] for i in labels]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T04:52:05.629757Z",
     "iopub.status.busy": "2024-06-15T04:52:05.629456Z",
     "iopub.status.idle": "2024-06-15T04:52:05.652868Z",
     "shell.execute_reply": "2024-06-15T04:52:05.652009Z",
     "shell.execute_reply.started": "2024-06-15T04:52:05.629732Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'overall_precision': 0.0,\n",
       " 'overall_recall': 0.0,\n",
       " 'overall_f1': 0.0,\n",
       " 'overall_accuracy': 1.0}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 24: Create dummy predictions and compute metrics\n",
    "predictions = labels.copy()\n",
    "predictions[2] = \"O\"\n",
    "metric.compute(predictions=[predictions], references=[labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T04:52:05.657188Z",
     "iopub.status.busy": "2024-06-15T04:52:05.656817Z",
     "iopub.status.idle": "2024-06-15T04:52:05.663968Z",
     "shell.execute_reply": "2024-06-15T04:52:05.663146Z",
     "shell.execute_reply.started": "2024-06-15T04:52:05.657161Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Step 25: Define compute_metrics function for evaluation during training\n",
    "import numpy as np\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": all_metrics[\"overall_precision\"],\n",
    "        \"recall\": all_metrics[\"overall_recall\"],\n",
    "        \"f1\": all_metrics[\"overall_f1\"],\n",
    "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T04:52:05.665190Z",
     "iopub.status.busy": "2024-06-15T04:52:05.664946Z",
     "iopub.status.idle": "2024-06-15T04:52:05.675552Z",
     "shell.execute_reply": "2024-06-15T04:52:05.674675Z",
     "shell.execute_reply.started": "2024-06-15T04:52:05.665169Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Step 26: Create id2label and label2id mappings for the model\n",
    "id2label = {i: label for i, label in enumerate(label_names)}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "# print(id2label)\n",
    "# print(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T04:52:05.676980Z",
     "iopub.status.busy": "2024-06-15T04:52:05.676717Z",
     "iopub.status.idle": "2024-06-15T04:52:06.110029Z",
     "shell.execute_reply": "2024-06-15T04:52:06.109103Z",
     "shell.execute_reply.started": "2024-06-15T04:52:05.676957Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Step 27: Load the token classification model from HuggingFace\n",
    "from transformers import AutoModelForTokenClassification\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T04:52:06.111548Z",
     "iopub.status.busy": "2024-06-15T04:52:06.111232Z",
     "iopub.status.idle": "2024-06-15T04:52:06.118412Z",
     "shell.execute_reply": "2024-06-15T04:52:06.117491Z",
     "shell.execute_reply.started": "2024-06-15T04:52:06.111518Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wandb', 'state.db', 'results']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 28: List files in the current directory (for debugging)\n",
    "import os\n",
    "os.listdir(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T04:52:06.119766Z",
     "iopub.status.busy": "2024-06-15T04:52:06.119498Z",
     "iopub.status.idle": "2024-06-15T04:52:06.690348Z",
     "shell.execute_reply": "2024-06-15T04:52:06.689003Z",
     "shell.execute_reply.started": "2024-06-15T04:52:06.119742Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './tmp_trainer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshutil\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrmtree\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./tmp_trainer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/shutil.py:715\u001b[0m, in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[1;32m    713\u001b[0m     orig_st \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlstat(path)\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m--> 715\u001b[0m     \u001b[43monerror\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/shutil.py:713\u001b[0m, in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;66;03m# Note: To guard against symlink races, we use the standard\u001b[39;00m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;66;03m# lstat()/open()/fstat() trick.\u001b[39;00m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 713\u001b[0m     orig_st \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    715\u001b[0m     onerror(os\u001b[38;5;241m.\u001b[39mlstat, path, sys\u001b[38;5;241m.\u001b[39mexc_info())\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './tmp_trainer'"
     ]
    }
   ],
   "source": [
    "# Step 29: Remove previous trainer directory if exists\n",
    "import shutil\n",
    "shutil.rmtree('./tmp_trainer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-15T04:52:06.691480Z",
     "iopub.status.idle": "2024-06-15T04:52:06.691951Z",
     "shell.execute_reply": "2024-06-15T04:52:06.691731Z",
     "shell.execute_reply.started": "2024-06-15T04:52:06.691712Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Step 30: Trainer setup placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-15T04:52:06.694090Z",
     "iopub.status.idle": "2024-06-15T04:52:06.694697Z",
     "shell.execute_reply": "2024-06-15T04:52:06.694383Z",
     "shell.execute_reply.started": "2024-06-15T04:52:06.694361Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Step 31: Import necessary modules for training\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForTokenClassification\n",
    "from transformers import Trainer\n",
    "# Step 32: Load the model and tokenizer again (redundant, but kept for clarity)\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "model_checkpoint = \"google-bert/bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "# Step 33: Define training arguments\n",
    "from transformers import TrainingArguments\n",
    "args = TrainingArguments(\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,  # Adjusted learning rate\n",
    "    per_device_train_batch_size=16,  # Adjusted batch size\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,  # Adjusted number of epochs\n",
    "    weight_decay=0.01, # Limit the total amount of checkpoints. Deletes the older checkpoints.\n",
    "    load_best_model_at_end=True,  # Load the best model found at the end of training\n",
    "    metric_for_best_model=\"f1\",  # Use F1 score to determine the best model\n",
    ")\n",
    "# Step 34: Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-15T04:52:06.696537Z",
     "iopub.status.idle": "2024-06-15T04:52:06.697020Z",
     "shell.execute_reply": "2024-06-15T04:52:06.696801Z",
     "shell.execute_reply.started": "2024-06-15T04:52:06.696782Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Step 35: Train the model and push to HuggingFace Hub\n",
    "trainer.train()\n",
    "trainer.push_to_hub(commit_message=\"Training complete\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
